{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks: Simple\n",
    "\n",
    "## Chapter 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dot Product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from math import exp\n",
    "\n",
    "def dot_product(xs: List[Float], ys: List[Float]) -> float:\n",
    "    \"\"\"\n",
    "    Dot product of two lists.\n",
    "    \"\"\"\n",
    "    return sum(x * y for x, y in zip(xs, ys))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sigmoid Activation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x: float) -> float:\n",
    "    \"\"\"\n",
    "    Sigmoid activation function.\n",
    "    \"\"\"\n",
    "    return 1 / (1 + exp(-x))\n",
    "\n",
    "def derivative_sigmoid(x: float) -> float:\n",
    "    \"\"\"\n",
    "    Derivative of sigmoid activation function.\n",
    "    \"\"\"\n",
    "    return sigmoid(x) * (1 - sigmoid(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neuron\n",
    "\n",
    "Must have \n",
    "\n",
    "* weights\n",
    "* delta\n",
    "* learning_rate\n",
    "* cache of last output\n",
    "* activation_function\n",
    "* derivative of activation_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable\n",
    "\n",
    "\n",
    "class Neuron:\n",
    "    \"\"\"\n",
    "    Basic unit for a neural network. Must have weights, activation function, derivative of activation function,\n",
    "    learning rate, cache of last output, and delta.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        weights: List[float],\n",
    "        learning_rate: float,\n",
    "        activation_function: Callable[[float], float],\n",
    "        derivative_activation_function: Callable[[float], float],\n",
    "    ) -> None:\n",
    "        self.weights: List[float] = weights\n",
    "        self.activation_function: Callable[[float], float] = activation_function\n",
    "        self.derivative_activation_function: Callable[\n",
    "            [float], float\n",
    "        ] = derivative_activation_function\n",
    "        self.learning_rate: float = learning_rate\n",
    "        self.output_cache: float = 0.0\n",
    "        self.delta: float = 0.0\n",
    "\n",
    "    def output(self, inputs: List[float]) -> float:\n",
    "        \"\"\"\n",
    "        Feed forward pass of neuron.\n",
    "        \"\"\"\n",
    "        self.output_cache = dot_product(inputs, self.weights)\n",
    "        return self.activation_function(self.output_cache)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Layer\n",
    "\n",
    "A layer must have:\n",
    "\n",
    "* neurons\n",
    "* output cache (after the activation function is applied to neuron's output)\n",
    "* previous layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "from typing import Optional\n",
    "from random import random\n",
    "\n",
    "\n",
    "class Layer:\n",
    "    \"\"\"\n",
    "    Base class for a neural network layer. Must know the previous layer, the neurons, and an output cache (after activation function).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        previous_layer: Optional[Layer],\n",
    "        num_neurons: int,\n",
    "        learning_rate: float,\n",
    "        activation_function: Callable[[float], float],\n",
    "        derivative_activation_function: Callable[[float], float],\n",
    "    ) -> None:\n",
    "        self.previous_layer: Optional[Layer] = previous_layer\n",
    "        self.neurons: List[Neuron] = []\n",
    "\n",
    "        # Add neurons\n",
    "        for i in range(num_neurons):\n",
    "            if previous_layer is None:\n",
    "                random_weights: List[float] = []\n",
    "            else:\n",
    "                # Each neuron is connected to every neuron in previous layer\n",
    "                random_weights = [random() for _ in range(len(previous_layer.neurons))]\n",
    "            neuron: Neuron = Neuron(\n",
    "                random_weights,\n",
    "                learning_rate,\n",
    "                activation_function,\n",
    "                derivative_activation_function,\n",
    "            )\n",
    "            self.neurons.append(neuron)\n",
    "        # Initialize empty output cache\n",
    "        self.output_cache: List[float] = [0.0 for _ in range(num_neurons)]\n",
    "\n",
    "    def outputs(self, inputs: List[float]) -> List[float]:\n",
    "        \"\"\"\n",
    "        Calculate outputs of all neurons in layer.\n",
    "        \"\"\"\n",
    "        if self.previous_layer is None:  # This is an input layer\n",
    "            self.output_cache = inputs\n",
    "        else:\n",
    "            self.output_cache = [n.output(inputs) for n in self.neurons]\n",
    "        return self.output_cache\n",
    "\n",
    "    def calculate_deltas_for_output_layer(self, expected: List[float]) -> None:\n",
    "        \"\"\"\n",
    "        Calculate deltas for output layer. Delta = f'(output_cache) * error\n",
    "        \n",
    "        f'(output_cache) is derivative of activation with respect to output cache\n",
    "        error is expected - actual\n",
    "        \"\"\"\n",
    "        for n in range(len(self.neurons)):\n",
    "            # Call the derivative of the activation function on the neuron's output and\n",
    "            # multiply by the expected value\n",
    "            self.neurons[n].delta = self.neurons[n].derivative_activation_function(\n",
    "                self.neurons[n].output_cache\n",
    "            ) * (expected[n] - self.output_cache[n])\n",
    "\n",
    "    def calculate_deltas_for_hidden_layer(self, next_layer: Layer) -> None:\n",
    "        \"\"\"\n",
    "        Calculate deltas for hiddne layer. Delta = f'(output_cache) * (next_weights * next_deltas)\n",
    "        \"\"\"\n",
    "        for index, neuron in enumerate(self.neurons):\n",
    "            next_weights: List[float] = [n.weights[index] for n in next_layer.neurons]\n",
    "            next_deltas: List[float] = [n.delta for n in next_layer.neurons]\n",
    "            sum_weights_and_deltas: float = dot_product(next_weights, next_deltas)\n",
    "            neuron.delta = (\n",
    "                neuron.derivative_activation_function(neuron.output_cache)\n",
    "                * sum_weights_and_deltas\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypeVar, Tuple\n",
    "from functools import reduce\n",
    "\n",
    "# Output type of interpretation of neural network\n",
    "T = TypeVar(\"T\")\n",
    "\n",
    "\n",
    "class Network:\n",
    "    \"\"\"\n",
    "    Base class for neural network. Must keep state of layers.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        layer_structure: List[int],\n",
    "        learning_rate: float,\n",
    "        activation_function: Callable[[float], float] = sigmoid,\n",
    "        derivative_activation_function: Callable[[float], float] = derivative_sigmoid,\n",
    "    ) -> None:\n",
    "        if len(layer_structure) < 3:\n",
    "            raise ValueError(\n",
    "                \"Error: Should be at least 3 layers (input, hidden, output)\"\n",
    "            )\n",
    "\n",
    "        self.layers: List[layer] = []\n",
    "        # Input layer\n",
    "        input_layer: Layer = Layer(\n",
    "            previous_layer=None,\n",
    "            num_neurons=layer_structure[0],\n",
    "            learning_rate=learning_rate,\n",
    "            activation_function=activation_function,\n",
    "            derivative_activation_function=derivative_activation_function,\n",
    "        )\n",
    "        self.layers.append(input_layer)\n",
    "\n",
    "        # Hidden layers and output layer\n",
    "        for previous, num_neurons in enumerate(layer_structure[1::]):\n",
    "            next_layer = Layer(\n",
    "                previous_layer=self.layers[previous],\n",
    "                num_neurons=num_neurons,\n",
    "                learning_rate=learning_rate,\n",
    "                activation_function=activation_function,\n",
    "                derivative_activation_function=derivative_activation_function,\n",
    "            )\n",
    "            self.layers.append(next_layer)\n",
    "\n",
    "    def outputs(self, input: List[float]) -> List[float]:\n",
    "        \"\"\"\n",
    "        Calculate outputs for entire network.\n",
    "        \"\"\"\n",
    "        # Pushes input data to first layer, then output from first as input to second, output from second\n",
    "        # as input to third and so on\n",
    "        return reduce(\n",
    "            lambda inputs, layer: layer.outputs(inputs),  # Function\n",
    "            self.layers,  # Sequence\n",
    "            input,  # Initial\n",
    "        )\n",
    "\n",
    "    def backpropagate(self, expected: List[float]) -> None:\n",
    "        \"\"\"\n",
    "        Calculate delta (change) for each neuron in each layer. Move backwards through the network\n",
    "        from output towards input.\n",
    "        \"\"\"\n",
    "        # Calculate delta for output\n",
    "        last_layer: int = len(self.layers) - 1\n",
    "        self.layers[last_layer].calculate_deltas_for_output_layer(expected)\n",
    "\n",
    "        # Calculate delta for hidden layers moving from end to beginning\n",
    "        for l in range(last_layer - 1, 0, -1):\n",
    "            # Send in previous layer\n",
    "            self.layers[l].calculate_deltas_for_hidden_layer(self.layers[l + 1])\n",
    "\n",
    "    def update_weights(self) -> None:\n",
    "        \"\"\"\n",
    "        Apply formula to update the weights of all neurons.\n",
    "        \n",
    "        weight = weight + learning_rate * input * neuron_delta\n",
    "        \"\"\"\n",
    "        for layer in self.layers[1:]:\n",
    "            for neuron in layer.neurons:\n",
    "                for w in range(len(neuron.weights)):\n",
    "                    neuron.weights[w] = neuron.weights[w] + (\n",
    "                        neuron.learning_rate\n",
    "                        * layer.previous_layer.output_cache[w]\n",
    "                        * neuron.delta\n",
    "                    )\n",
    "\n",
    "    def train(self, inputs: List[List[float]], expecteds: List[List[float]]) -> None:\n",
    "        \"\"\"\n",
    "        Train the network to map from the inputs to the expecteds using the neuron's weights.\n",
    "        \"\"\"\n",
    "        for location, xs in enumerate(inputs):\n",
    "            ys: List[float] = expecteds[location]\n",
    "            outs: List[float] = self.outputs(xs)\n",
    "            # Backpropagate to calculate deltas\n",
    "            self.backpropagate(ys)\n",
    "            # Update weights with deltas\n",
    "            self.update_weights()\n",
    "\n",
    "    def validate(\n",
    "        self,\n",
    "        inputs: List[List[float]],\n",
    "        expecteds: List[T],\n",
    "        interpret_output: Callable[[List[float]], T],\n",
    "    ) -> Tuple[int, int, float]:\n",
    "        \"\"\"\n",
    "        Validate the network's outputs on a dataset. Returns the correct number of trials and the percentage\n",
    "        correct out of the total. Only applicate for classification tasks. \n",
    "        The callable must interpret the outputs in the problem context.\n",
    "        \"\"\"\n",
    "        correct: int = 0\n",
    "        for input, expected in zip(inputs, expecteds):\n",
    "            # Calculate output from input\n",
    "            outs: List[float] = self.outputs(input)\n",
    "            # Interpret the floats in the data context.\n",
    "            result: T = interpret_output(outs)\n",
    "\n",
    "            if result == expected:\n",
    "                correct += 1\n",
    "\n",
    "        percentage: float = correct / len(inputs)\n",
    "        return correct, len(inputs), percentage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Scaling\n",
    "\n",
    "We will scale inputs to between 0 and 1 for input to the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.0, 0.0, 1.0, 1.0], [1.0, 1.0, 0.0, 0.0], [0.5, 0.5, 0.5, 0.5]]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def normalize_by_feature_scaling(dataset: List[[List[float]]]) -> None:\n",
    "    for col_num in range(len(dataset[0])):\n",
    "        column: List[float] = [row[col_num] for row in dataset]\n",
    "        maximum, minimum = max(column), min(column)\n",
    "        for row_num in range(len(column)):\n",
    "            dataset[row_num][col_num] = (dataset[row_num][col_num] - minimum) / (maximum - minimum)\n",
    "            \n",
    "d = [[2, 4, 3, 8], [4, 6, 2, 7], [3, 5, 2.5, 7.5]]\n",
    "normalize_by_feature_scaling(d)\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduce(lambda input, output: input + output, [4, 5, 6], 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing with Classic Iris Dataset\n",
    "\n",
    "This dataset serves as a benchmark for classification models. It is simple, yet will let us ascertain if our model is behaving as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from random import shuffle\n",
    "\n",
    "def read_iris():\n",
    "    \"\"\"\n",
    "    Read in the iris data file as list of lists.\n",
    "    \"\"\"\n",
    "    iris_parameters: List[List[float]] = []\n",
    "    iris_classifications: List[List[float]] = []\n",
    "    iris_species: List[str] = []\n",
    "        \n",
    "    with open('iris.csv', mode='r') as iris_file:\n",
    "        irises: List = list(csv.reader(iris_file))\n",
    "        shuffle(irises) # Mix randomly\n",
    "        for iris in irises:\n",
    "            # The first 4 columns are the features\n",
    "            parameters: List[float] = [float(n) for n in iris[:4]]\n",
    "            iris_parameters.append(parameters)\n",
    "            species: str= iris[4]\n",
    "            if species == 'Iris-setosa':\n",
    "                iris_classifications.append([1.0, 0.0, 0.0])\n",
    "            elif species == 'Iris-versicolor':\n",
    "                iris_classifications.append([0.0, 1.0, 0.0])\n",
    "            elif species == 'Iris-virginica':\n",
    "                iris_classifications.append([0.0, 0.0, 1.0])\n",
    "            iris_species.append(species)\n",
    "            \n",
    "    normalize_by_feature_scaling(iris_parameters)\n",
    "    \n",
    "    return iris_parameters, iris_classifications, iris_species\n",
    "\n",
    "iris_parameters, iris_classifications, iris_species = read_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'Iris-versicolor': 50, 'Iris-setosa': 50, 'Iris-virginica': 50})"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter(iris_species)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max([n[0] for n in iris_parameters])\n",
    "min([n[0] for n in iris_parameters])\n",
    "\n",
    "max([n[1] for n in iris_parameters])\n",
    "min([n[1] for n in iris_parameters])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiate Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_network: Network = Network(layer_structure=[4, 6, 3], learning_rate=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement Interpretation of Model Output for Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iris_interpret_output(output: List[float]) -> str:\n",
    "    \"\"\"\n",
    "    Translate float output from network to string species classification.\n",
    "    \"\"\"\n",
    "    if output.index(max(output)) == 0:\n",
    "        return 'Iris-setosa'\n",
    "    elif output.index(max(output)) == 1:\n",
    "        return 'Iris-versicolor'\n",
    "    elif output.index(max(output)) == 2:\n",
    "        return 'Iris-virginica'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 120\n",
    "\n",
    "iris_trainers: List[List[float]] = iris_parameters[:train_size]\n",
    "iris_trainers_expected: List[List[float]] = iris_classifications[:train_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(50):\n",
    "    iris_network.train(inputs=iris_trainers, expecteds=iris_trainers_expected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_testers = iris_parameters[train_size:]\n",
    "iris_testers_species = iris_species[train_size:]\n",
    "\n",
    "iris_results = iris_network.validate(\n",
    "    inputs=iris_testers,\n",
    "    expecteds=iris_testers_species,\n",
    "    interpret_output=iris_interpret_output,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28 correct out of 30 total. 93.33%\n"
     ]
    }
   ],
   "source": [
    "print(f\"{iris_results[0]} correct out of {iris_results[1]} total. {iris_results[2] * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9883140840958653, 0.17155672732408708, 2.8872456012232333e-05]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_network.outputs(input=iris_testers[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0, 0.0, 0.0]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_testers_expected[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True  Guess: Iris-setosa        Actual: Iris-setosa        Probabability: 0.99.\n",
      "True  Guess: Iris-setosa        Actual: Iris-setosa        Probabability: 0.97.\n",
      "True  Guess: Iris-setosa        Actual: Iris-setosa        Probabability: 0.99.\n",
      "True  Guess: Iris-setosa        Actual: Iris-setosa        Probabability: 0.96.\n",
      "True  Guess: Iris-virginica     Actual: Iris-virginica     Probabability: 0.86.\n",
      "False Guess: Iris-versicolor    Actual: Iris-virginica     Probabability: 0.60.\n",
      "True  Guess: Iris-setosa        Actual: Iris-setosa        Probabability: 0.99.\n",
      "False Guess: Iris-virginica     Actual: Iris-versicolor    Probabability: 0.47.\n",
      "True  Guess: Iris-virginica     Actual: Iris-virginica     Probabability: 0.89.\n",
      "True  Guess: Iris-virginica     Actual: Iris-virginica     Probabability: 0.80.\n",
      "True  Guess: Iris-versicolor    Actual: Iris-versicolor    Probabability: 0.80.\n",
      "True  Guess: Iris-versicolor    Actual: Iris-versicolor    Probabability: 0.67.\n",
      "True  Guess: Iris-setosa        Actual: Iris-setosa        Probabability: 0.99.\n",
      "True  Guess: Iris-versicolor    Actual: Iris-versicolor    Probabability: 0.70.\n",
      "True  Guess: Iris-setosa        Actual: Iris-setosa        Probabability: 1.00.\n",
      "True  Guess: Iris-virginica     Actual: Iris-virginica     Probabability: 0.50.\n",
      "True  Guess: Iris-setosa        Actual: Iris-setosa        Probabability: 1.00.\n",
      "True  Guess: Iris-virginica     Actual: Iris-virginica     Probabability: 0.67.\n",
      "True  Guess: Iris-versicolor    Actual: Iris-versicolor    Probabability: 0.82.\n",
      "True  Guess: Iris-virginica     Actual: Iris-virginica     Probabability: 0.84.\n",
      "True  Guess: Iris-virginica     Actual: Iris-virginica     Probabability: 0.88.\n",
      "True  Guess: Iris-virginica     Actual: Iris-virginica     Probabability: 0.84.\n",
      "True  Guess: Iris-setosa        Actual: Iris-setosa        Probabability: 1.00.\n",
      "True  Guess: Iris-setosa        Actual: Iris-setosa        Probabability: 0.99.\n",
      "True  Guess: Iris-setosa        Actual: Iris-setosa        Probabability: 0.99.\n",
      "True  Guess: Iris-versicolor    Actual: Iris-versicolor    Probabability: 0.78.\n",
      "True  Guess: Iris-setosa        Actual: Iris-setosa        Probabability: 0.99.\n",
      "True  Guess: Iris-versicolor    Actual: Iris-versicolor    Probabability: 0.60.\n",
      "True  Guess: Iris-virginica     Actual: Iris-virginica     Probabability: 0.80.\n",
      "True  Guess: Iris-versicolor    Actual: Iris-versicolor    Probabability: 0.65.\n"
     ]
    }
   ],
   "source": [
    "species_dict = {0: 'Iris-setosa', 1:'Iris-versicolor', 2: 'Iris-virginica'}\n",
    "out = [iris_network.outputs(iris) for iris in iris_testers]\n",
    "probs = [max(o) for o in out]\n",
    "classes = [species_dict[iris.index(max(iris))] for iris in out]\n",
    "\n",
    "for guess, correct, p in zip(classes, iris_testers_species, probs):\n",
    "    print(f'{\"True\" if guess == correct else \"False\":5} Guess: {guess:18} Actual: {correct:18} Probabability: {p:.2f}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifying Wine Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def read_wine():\n",
    "    \"\"\"\n",
    "    Read in the wine data set and return features, expected outputs, and species names.\n",
    "    \"\"\"\n",
    "    wine_parameters: List[List[float]] = []\n",
    "    wine_classifications: List[List[float]] = []\n",
    "    wine_species: List[int] = []\n",
    "    with open('wine.csv', mode='r') as wine_file:\n",
    "        wines: List = list(csv.reader(wine_file, quoting=csv.QUOTE_NONNUMERIC))\n",
    "        shuffle(wines) # get our lines of data in random order\n",
    "        for wine in wines:\n",
    "            parameters: List[float] = [float(n) for n in wine[1:14]]\n",
    "            wine_parameters.append(parameters)\n",
    "            species: int = int(wine[0])\n",
    "            if species == 1:\n",
    "                wine_classifications.append([1.0, 0.0, 0.0])\n",
    "            elif species == 2:\n",
    "                wine_classifications.append([0.0, 1.0, 0.0])\n",
    "            else:\n",
    "                wine_classifications.append([0.0, 0.0, 1.0])\n",
    "            wine_species.append(species)\n",
    "    normalize_by_feature_scaling(wine_parameters)\n",
    "    return wine_parameters, wine_classifications, wine_species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_parameters, wine_classifications, wine_species = read_wine()\n",
    "\n",
    "def wine_interpret_output(output: List[float]) -> int:\n",
    "    \"\"\"\n",
    "    Interpret float outputs from wine neural network as species classifications.\n",
    "    \"\"\"\n",
    "    if max(output) == output[0]:\n",
    "        return 1\n",
    "    elif max(output) == output[1]:\n",
    "        return 2\n",
    "    else:\n",
    "        return 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 13 features in this dataset. We should use a larger, deeper neural network for this problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(wine_parameters[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 178 examples. We'll use the same training size of 120 observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "178"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(wine_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need as many neurons in the input layer as there are features. We need as many neurons in the output layer as there are species. The learning rate is set rather high in this example. Our network has a total of 4 layers, 1 input, 2 hidden, and 1 output. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.Network object at 0x1264b1400>\n"
     ]
    }
   ],
   "source": [
    "wine_network = Network(layer_structure=[13, 8, 16, 3], learning_rate=0.8)\n",
    "print(wine_network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_trainers = wine_parameters[:train_size]\n",
    "wine_trainers_expected = wine_classifications[:train_size]\n",
    "\n",
    "for _ in range(50):\n",
    "    wine_network.train(inputs=wine_trainers, expecteds=wine_trainers_expected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_testers = wine_parameters[train_size:]\n",
    "wine_testers_species = wine_species[train_size:]\n",
    "\n",
    "wine_results = wine_network.validate(\n",
    "    inputs=wine_testers,\n",
    "    expecteds=wine_testers_species,\n",
    "    interpret_output=wine_interpret_output,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53 correct out of 58 total. 91.38%\n"
     ]
    }
   ],
   "source": [
    "print(f\"{wine_results[0]} correct out of {wine_results[1]} total. {wine_results[2] * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True  Guess:  3 Actual:  3 Probabability: 0.99.\n",
      "True  Guess:  2 Actual:  2 Probabability: 1.00.\n",
      "True  Guess:  3 Actual:  3 Probabability: 0.98.\n",
      "True  Guess:  1 Actual:  1 Probabability: 0.98.\n",
      "True  Guess:  3 Actual:  3 Probabability: 0.98.\n",
      "True  Guess:  1 Actual:  1 Probabability: 0.98.\n",
      "True  Guess:  1 Actual:  1 Probabability: 0.98.\n",
      "True  Guess:  1 Actual:  1 Probabability: 0.98.\n",
      "True  Guess:  2 Actual:  2 Probabability: 1.00.\n",
      "True  Guess:  2 Actual:  2 Probabability: 0.59.\n",
      "False Guess:  1 Actual:  3 Probabability: 0.58.\n",
      "True  Guess:  3 Actual:  3 Probabability: 0.99.\n",
      "False Guess:  1 Actual:  2 Probabability: 0.53.\n",
      "True  Guess:  3 Actual:  3 Probabability: 0.99.\n",
      "True  Guess:  1 Actual:  1 Probabability: 0.96.\n",
      "True  Guess:  2 Actual:  2 Probabability: 0.94.\n",
      "True  Guess:  1 Actual:  1 Probabability: 0.94.\n",
      "True  Guess:  2 Actual:  2 Probabability: 0.98.\n",
      "True  Guess:  2 Actual:  2 Probabability: 1.00.\n",
      "True  Guess:  2 Actual:  2 Probabability: 0.85.\n",
      "True  Guess:  3 Actual:  3 Probabability: 0.94.\n",
      "True  Guess:  3 Actual:  3 Probabability: 0.96.\n",
      "False Guess:  1 Actual:  2 Probabability: 0.65.\n",
      "True  Guess:  2 Actual:  2 Probabability: 1.00.\n",
      "True  Guess:  2 Actual:  2 Probabability: 0.99.\n",
      "True  Guess:  1 Actual:  1 Probabability: 0.97.\n",
      "True  Guess:  1 Actual:  1 Probabability: 0.97.\n",
      "True  Guess:  2 Actual:  2 Probabability: 1.00.\n",
      "True  Guess:  3 Actual:  3 Probabability: 0.98.\n",
      "True  Guess:  2 Actual:  2 Probabability: 0.99.\n",
      "True  Guess:  1 Actual:  1 Probabability: 0.98.\n",
      "True  Guess:  2 Actual:  2 Probabability: 0.98.\n",
      "True  Guess:  1 Actual:  1 Probabability: 0.98.\n",
      "True  Guess:  1 Actual:  1 Probabability: 0.98.\n",
      "True  Guess:  3 Actual:  3 Probabability: 0.99.\n",
      "False Guess:  2 Actual:  1 Probabability: 0.84.\n",
      "True  Guess:  3 Actual:  3 Probabability: 0.98.\n",
      "True  Guess:  1 Actual:  1 Probabability: 0.96.\n",
      "True  Guess:  1 Actual:  1 Probabability: 0.98.\n",
      "True  Guess:  1 Actual:  1 Probabability: 0.98.\n",
      "True  Guess:  1 Actual:  1 Probabability: 0.95.\n",
      "True  Guess:  3 Actual:  3 Probabability: 0.99.\n",
      "False Guess:  1 Actual:  2 Probabability: 0.66.\n",
      "True  Guess:  2 Actual:  2 Probabability: 1.00.\n",
      "True  Guess:  1 Actual:  1 Probabability: 0.98.\n",
      "True  Guess:  2 Actual:  2 Probabability: 1.00.\n",
      "True  Guess:  3 Actual:  3 Probabability: 0.98.\n",
      "True  Guess:  1 Actual:  1 Probabability: 0.95.\n",
      "True  Guess:  2 Actual:  2 Probabability: 1.00.\n",
      "True  Guess:  1 Actual:  1 Probabability: 0.97.\n",
      "True  Guess:  1 Actual:  1 Probabability: 0.96.\n",
      "True  Guess:  1 Actual:  1 Probabability: 0.98.\n",
      "True  Guess:  1 Actual:  1 Probabability: 0.98.\n",
      "True  Guess:  1 Actual:  1 Probabability: 0.98.\n",
      "True  Guess:  2 Actual:  2 Probabability: 0.79.\n",
      "True  Guess:  3 Actual:  3 Probabability: 0.94.\n",
      "True  Guess:  2 Actual:  2 Probabability: 1.00.\n",
      "True  Guess:  2 Actual:  2 Probabability: 1.00.\n"
     ]
    }
   ],
   "source": [
    "species_dict = {0: 1, 1:2, 2:3}\n",
    "out = [wine_network.outputs(wine) for wine in wine_testers]\n",
    "probs = [max(o) for o in out]\n",
    "classes = [species_dict[wine.index(max(wine))] for wine in out]\n",
    "\n",
    "for guess, correct, p in zip(classes, wine_testers_species, probs):\n",
    "    print(f'{\"True\" if guess == correct else \"False\":5} Guess: {guess:2} Actual: {correct:2} Probabability: {p:.2f}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Speeding Up Neural Networks\n",
    "\n",
    "Dedicated hardware has resulted in signicant neural network speed-ups. \n",
    "\n",
    "* GPU: Graphics processing units for highly parallelizable operations\n",
    "* SIMD: single instruction, multiple data instructions in numpy allow multiple pieces of data to be processed at once -> vector instructions\n",
    "* Numpy automatically chooses optimizations based on underlying architecture. \n",
    "* Use optimized implementations when working on actual problems.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network Problems\n",
    "\n",
    "The largest shortcoming may be a lack of interpretability. We know that neural networks achieve high accuracy, but little about why this they are effective (this holds across different ml models). \n",
    "\n",
    "We can look at individual weights in the network, but this does not provide much insight because of the large number of weights and multiple hidden layers. \n",
    "\n",
    "Neural networks require massive amounts of data to achieve high accuracy. For more complex applications - such as image classification - a neural network requires orders of magnitude more data than for our simple problem because it must learn many more features. This application - image classification - would also require a significantly larger network to learn the features. \n",
    "\n",
    "Neural networks are computationally expensive because of the large number of cacluations. SIMD and GPU hardware is essential to training of modern neural networks. \n",
    "\n",
    "Using the network is not as computationally intensive as training. After you train your network, inference - making predictions - does not require significant resources.\n",
    "\n",
    "# Extensions\n",
    "\n",
    "There are many other types of neural networks for tasks such as image classification and speech recognition.\n",
    "\n",
    "* Convolutional neural networks that process neighboring floats simulataneously\n",
    "* Recurrent neural networks that process data moving from one float to the next, considering the data sequence. \n",
    "* Bias added to neurons (in addition to weight) provide a constant input allowing next layer's output to represent more functions. (Bias is still learned through training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applications\n",
    "\n",
    "Did not become common place until later this decade thanks to availability of data and computer hardware (and some algorithm changes). One of the highest potential areas in machine learning because they are effective.\n",
    "\n",
    "## Practical Voice Recognition\n",
    "\n",
    "## Image Recognition and Tagging\n",
    "\n",
    "## Optical Character Recognition\n",
    "\n",
    "## Recommendation systems\n",
    "\n",
    "## Outcome of real-world events\n",
    "\n",
    "## Any problem that can be represented as an unknown function to be learned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hardest part of neural networks may be deciding on the structure of the network. Empirical results are more effective than theory for neural networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
